{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import json\n",
    "import urllib\n",
    "import xlrd\n",
    "import boto\n",
    "from boto.s3.key import Key\n",
    "import csv\n",
    "import datadotworld as dw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "host = \"https://esa.un.org\"\n",
    "\n",
    "base_url = host + \"/unpd/wpp/Download\"\n",
    "\n",
    "sub_urls_to_crawl = '''\n",
    "/SpecialAggregates/Ecological/\n",
    "/Standard/Mortality/\n",
    "/Standard/Errata/\n",
    "/Standard/ASCII/\n",
    "/SpecialAggregates/Political/\n",
    "/Standard/Interpolated/\n",
    "/Probabilistic/Population/\n",
    "/Standard/Fertility/\n",
    "/Other/MLT/\n",
    "/Standard/Migration/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_sheets(filepath):\n",
    "    xl_workbook = xlrd.open_workbook(filepath)\n",
    "    out_data = {}\n",
    "    for sheet in xl_workbook.sheet_names():\n",
    "        in_context = False\n",
    "        out_data[sheet] = []\n",
    "        xl_sheet = xl_workbook.sheet_by_name(sheet)\n",
    "        num_cols = xl_sheet.ncols   # Number of columns\n",
    "        for row_idx in range(0, xl_sheet.nrows):\n",
    "            row = []\n",
    "            for col_idx in range(0, num_cols):  # Iterate through columns\n",
    "                cell_obj = xl_sheet.cell(row_idx, col_idx)  # Get cell object by row, col \n",
    "                if cell_obj.value == 'Index':\n",
    "                    in_context = True\n",
    "                    \n",
    "                if in_context:\n",
    "                    row.append(cell_obj.value)\n",
    "            if in_context:\n",
    "                out_data[sheet].append(row)\n",
    "                \n",
    "    # remove empty\n",
    "    empty = []\n",
    "    for key, rows in out_data.items():\n",
    "        if len(rows) == 0:\n",
    "            empty.append(key)\n",
    "    for e in empty:\n",
    "        del out_data[e]\n",
    "    return out_data\n",
    "\n",
    "#out_data = extract_sheets(\"test_data.XLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://brianray.s3.amazonaws.com:443/test_dataXLS_SOMETEST.csv'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_to_s3(orginal_file_name, key, rows):\n",
    "    \n",
    "    new_file_name = '{}_{}.csv'.format(orginal_file_name.replace(\".\", \"\"), key) \n",
    "    with open(new_file_name, 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile)\n",
    "        spamwriter.writerows(rows)\n",
    "        \n",
    "    s3 = boto.connect_s3()\n",
    "    b = s3.get_bucket('brianray')\n",
    "    k = Key(b)\n",
    "    k.key = new_file_name\n",
    "    k.set_contents_from_filename(new_file_name)\n",
    "    k.set_acl('public-read')\n",
    "    return k.generate_url(expires_in=0, query_auth=False)\n",
    "    \n",
    "#url = save_to_s3(\"test_data.XLS\", \"SOMETEST\", [[\"test\", \"count\"], [\"a\", 3], [\"b\", 4]])\n",
    "#url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_extraction(filepath):\n",
    "    data_dict = extract_sheets(filepath)\n",
    "    out_urls = {}\n",
    "    for k, v in data_dict.items():\n",
    "        out_url = save_to_s3(filepath, k, v)\n",
    "        out_urls[out_url.split(\"/\")[-1]] =  out_url\n",
    "    return out_urls\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def save(url):\n",
    "    r = requests.get(url)\n",
    "    file_name = url.split(\"/\")[-1:][0]\n",
    "    print(r.status_code)\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "    return run_extraction(file_name)\n",
    "\n",
    "#url = \"https://esa.un.org/unpd/wpp/DVD/Files/1_Indicators%20%28Standard%29/EXCEL_FILES/1_Population/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXES.XLS\"\n",
    "#urls = save(url)\n",
    "#urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = dw.api_client()\n",
    "\n",
    "def save_to_dataworld(title, description, tags, link):\n",
    "    data_args = dict(owner_id=\"brianray\",\n",
    "                     title=title[:30],\n",
    "                     description=description[:120],\n",
    "                     tags=tags,\n",
    "                     license='Other',\n",
    "                     visibility=\"PRIVATE\", # \"OPEN\"\n",
    "                     files=link)\n",
    "    print(data_args)\n",
    "    try:\n",
    "        client.create_dataset(**data_args)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    for sub in sub_urls_to_crawl.strip().split(\"\\n\"):\n",
    "        url = \"{}{}\".format(base_url, sub)\n",
    "        print(url)\n",
    "        r = requests.get(url)\n",
    "        print(r.status_code)\n",
    "        tree = html.fromstring(r.content)\n",
    "        json_str = tree.xpath(\"//script\")[2].text.split(\"filesArray = \")[1].split(\"}];\")[0] + \"}]\"\n",
    "        for file_group_dict in json.loads(json_str):\n",
    "            tags = [\"un\", \"united nations\"]\n",
    "            tags += file_group_dict['MajorGroup'].split()\n",
    "            tags.append(file_group_dict['MajorGroup'].replace(\" \", \"_\"))\n",
    "            path = \"{}{}\".format(host, urllib.parse.quote(file_group_dict['File1_Path']))\n",
    "            file_paths = save(path)\n",
    "            save_to_dataworld(\"United Nations {}\".format(file_group_dict['File1_Title']),\n",
    "                              file_group_dict['Description'],\n",
    "                              tags,\n",
    "                              file_paths)\n",
    "                              \n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://esa.un.org/unpd/wpp/Download/SpecialAggregates/Ecological/\n",
      "200\n",
      "200\n",
      "{'description': 'Total Population - Both Sexes. De facto population in a country, area or region as of 1 July of the year indicated. Figu', 'visibility': 'PRIVATE', 'tags': ['un', 'united nations', 'Population', 'indicators', 'Population_indicators'], 'files': {'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_MEDIUM%20VARIANT.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_MEDIUM%20VARIANT.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_ZERO-MIGRATION.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_ZERO-MIGRATION.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_ESTIMATES.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_ESTIMATES.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_HIGH%20VARIANT.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_HIGH%20VARIANT.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_LOW%20VARIANT.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_LOW%20VARIANT.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_CONSTANT-FERTILITY.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_CONSTANT-FERTILITY.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_NO%20CHANGE.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_NO%20CHANGE.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_CONSTANT-MORTALITY.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_CONSTANT-MORTALITY.csv', 'WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_INSTANT-REPLACEMENT.csv': 'https://brianray.s3.amazonaws.com:443/WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXESXLS_INSTANT-REPLACEMENT.csv'}, 'owner_id': 'brianray', 'title': 'United Nations Total Populatio', 'license': 'Other'}\n",
      "(400)\n",
      "Reason: Bad Request\n",
      "HTTP response headers: HTTPHeaderDict({'Server': 'nginx/1.8.1', 'Content-Length': '372', 'Date': 'Sun, 09 Apr 2017 23:11:56 GMT', 'Connection': 'keep-alive', 'Content-Type': 'application/json'})\n",
      "HTTP response body: {\"code\":400,\"message\":\"Invalid DatasetCreateRequest . Violations = [ConstraintViolationImpl{interpolatedMessage='Tag {ValidTagPattern.message}', propertyPath=tags[4].value, rootBeanClass=class world.data.api.dtos.pub.DatasetCreateRequest, messageTemplate='Tag {ValidTagPattern.message}'}] :: Tag {ValidTagPattern.message}\",\"details\":\"a9431595-a39d-4b31-b36c-8c6845a292ea\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
